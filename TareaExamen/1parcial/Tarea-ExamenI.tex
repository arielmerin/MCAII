\documentclass[letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amssymb, amsmath}
\usepackage{graphicx}
\usepackage{lipsum}
\usepackage{dsfont}
\usepackage[margin=1.5cm,
vmargin={1.5cm,1.3cm},
includefoot]{geometry}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage{tocloft}
\usepackage{upgreek}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{fancyhdr}
\usepackage{lmodern}
\usepackage{tcolorbox}
\usepackage{color}
\usepackage{tikz}
\tcbuselibrary{skins,breakable}
\pagestyle{fancy}

\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}														  
\newcommand{\V}{\mathds{V}}

\newcommand{\W}{\mathds{W}}

\newcommand{\F}{\mathds{F}}

\newcommand{\tq}{ \quad \cdot  \backepsilon \cdot \quad }

\newcommand{\ld}{\lim\limits_{x \to 0^{+}}}

\newcommand{\li}{\lim\limits_{x \to 0^{-}}}

\newcommand{\la}{\lim\limits_{x \to a}}

\newcommand{\R}{\mathds{R}}

\newcommand{\Po}{\mathds{P}_2(\mathds{R})}

\renewcommand{\*}{\cdot}

\newcommand{\Iden}{\begin{pmatrix}
		1 & 0 & 0\\
		0 & 1 & 0\\
		0 & 0 & 1 
\end{pmatrix}}
\newcommand{\T}{\begin{pmatrix}
		1 & 3 & 9 \\
		1 & 3 & 4 \\
		0 & 0 & 2 
\end{pmatrix} }

\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
	\hskip -\arraycolsep
	\let\@ifnextchar\new@ifnextchar
	\array{#1}}
\makeatother

\newtheorem{theorem}{Teorema}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definición}
              		   
\begin{document}

\setlength{\unitlength}{1cm}
\thispagestyle{empty}
\begin{picture}(19,3)
\put(-0.5,1.2){\includegraphics[scale=.20]{unam1.png}}
\put(16,1){\includegraphics[scale=.29]{fciencias1.png}}
\end{picture}

\begin{center}
\vspace{-114pt}
\textbf{\large Matemáticas para las Ciencias II}\\
\textbf{ Semestre 2020-2}\\
Prof. Pedro Porras Flores\\
Ayud. Irving Hernández Rosas \\
\textbf{Tarea-examen I}\\[0.2cm]
Kevin Ariel Merino Peña\footnote{317031326}\\ [0.2cm]
\end{center}
\vspace{-10pt}
\rule{19cm}{0.3mm}

\vspace{0.5cm}
\noindent Realice los siguientes ejercicios, escribiendo el procedimiento claramente. Y recuerden que la tarea-examen se entrega individual. 

\noindent1. Muestre que $\mathbb{P}_{2}(\mathbb{R}) = \{ c  + bx + ax^2  \,  \vert \, a,b,c \in \mathbb{R} \}$, es un espacio vectorial con la suma usual y la multiplicación por escalar usual, es decir:
\begin{align*}
     + \colon & \mathbb{P}_{2}(\mathbb{R}) \times \mathbb{P}_{2}(\mathbb{R}) \longrightarrow \mathbb{P}_{2}(\mathbb{R}) \\
    & (a_1 x^2 + b_1x + c_1 , a_2 x^2 + b_2x + c_2) \mapsto  (a_1 + a_2)x^2 + (b_1 + b_2)x + (c_1 + c_2). \\
    \mu \colon & \mathbb{R} \times \mathbb{P}_{2}(\mathbb{R}) \longrightarrow \mathbb{P}_{2}(\mathbb{R}) \\
    & (\alpha, (a_1 x^2 + b_1x + c_1)) \mapsto  (\alpha a_1)x^2 + (\alpha b_1)x + (\alpha c_1).
 \end{align*}
\begin{definition}
	Sea $ \V $ un conjunto no vacío con 2 operaciones definidas $ (+,\mu) $ y un campo $ \F = \R $ que cumple
	\begin{enumerate}
		\item Sean $ \vec{x}, \vec{y} \in \V $, entonces $ \vec{x} + \vec{y} = \vec{y} + \vec{x} $
		\item Sean $ \vec{x}, \vec{y}, \vec{z} \in \V $, entonces
		$ (\vec{x} + \vec{y}) + \vec{z} = \vec{x} + (\vec{y} + \vec{z}) $
		\item Existe $ \vec{0} \in \V \tq \vec{0} + \vec{x} = \vec{x}, \qquad \forall \vec{x} \in \V$
		\item Para todo $ \vec{x} \in \V $ existe $ \vec{y} \in \V $ tal que $ \vec{x} + \vec{y} = 0 $
		\item Para todo $ \vec{x} \in \V $ se cumple que $ \vec{1} \vec{x} = \vec{x} $ donde $ \vec{1} $ es el neutro multiplicativo de $ \F(\R) $
		\item Para todo $ \alpha, \beta \in \F $ y $ \vec{x} \in \V $ se cumple $ (\alpha\beta)\vec{x} = \alpha(\beta \vec{x}) $
		\item Para todo $ \alpha, \beta  \in \F$ y $ \vec{x} \in \V $ entonces $ (\alpha + \beta)\vec{x} = \alpha\vec{x} + \beta\vec{x} $
		\item Sea $ \alpha \in \F $ y $ \vec{x}, \vec{y} \in \V $, entonces $ \alpha(\vec{x} + \vec{y}) = \alpha\vec{x} + \alpha\vec{y} $
	\end{enumerate}
\end{definition}
Sean $ \vec{x}, \vec{y} \in \Po $, por demostrar $\vec{x} + \vec{y} = \vec{y} + \vec{x}  $, como los elementos de $ \Po $ son de la forma $ c + ax + bx^2$, entonces digamos que \[ \vec{x} = a_1 + a_2x + a_3x^2 \] \[ \vec{y} = b_1 + b_2x + b_3x^2 \]
\begin{align*}
	\vec{x} + \vec{y} &=  (a_1 + a_2x + a_3x^2) + (b_1 + b_2x + b_3x^2) && \text{Por definición de los vectores}\\
	\vec{x} + \vec{y} &=  (a_1 + b_1) + (a_2 + b_2)x + (a_3 + b_3)x^2&& \text{Por definición de la suma}\\
	\vec{x} + \vec{y} &=  (b_1 + a_1) + (b_2 + a_2)x + (b_3 + a_3)x^2&& \text{Porque los elementos en $ \R $ conmutan}\\
	\vec{x} + \vec{y} &=  (b_1 + b_2x + b_3x^2) + (a_1 + a_2x + a_3x^2) && \text{Por la definición de +}\\
	\vec{x} + \vec{y} &=  \vec{y} + \vec{x}&& \text{Por definición de los vectores}\\
\end{align*}
\begin{center}
	$ \therefore $ los elementos de $ \Po $ conmutan, \textit{i.e.} $ \vec{x} + \vec{y} = 	\vec{y} + \vec{x} $
\end{center}

Sean $ \vec{x}, \vec{y}, \vec{z} \in \V $ por demostrar $  (\vec{x} + \vec{y}) + \vec{z} = \vec{x} + (\vec{y} + \vec{z})$
como los elementos de $ \Po $ son de la forma $ c + ax + bx^2$, entonces digamos que \[ \vec{x} = a_1 + a_2x + a_3x^2 \] \[ \vec{y} = b_1 + b_2x + b_3x^2 \] \[ \vec{z} = c_1 + c_2x + c_3x^2 \]

\begin{align*}
	(\vec{x} + \vec{y}) + \vec{z} &= ( a_1 + a_2x + a_3x^2 + b_1 + b_2x + b_3x^2) + c_1 + c_2x + c_3x^2&& \text{Por definición de los vectores}\\
	(\vec{x} + \vec{y}) + \vec{z} &= ( (a_1 + b_1)  + (a_2 + b_2)x + (a_3 + b_3) x^2 ) + c_1 + c_2x + c_3x^2&& \text{Por definición de los + en $ \Po $}\\ 
	(\vec{x} + \vec{y}) + \vec{z} &= ((a_1 + b_1) + c_1)  + ((a_2 + b_2) + c_2 )x + ((a_3 + b_3) + c_3) x^2 && \text{Por definición de los + en $ \Po $}\\ 
	(\vec{x} + \vec{y}) + \vec{z} &= (a_1 + (b_1 + c_1))  + (a_2 + (b_2 + c_2))x + (a_3 + (b_3 + c_3)) x^2 && \text{Porque en $ \R $ la suma es asociativa}\\ 
	(\vec{x} + \vec{y}) + \vec{z} &= a_1 + (b_1 + c_1)  + a_2x + (b_2 + c_2)x + a_3x^2 + (b_3 + c_3)x^2 && \text{Emplendo la definición de suma}\\ 
	(\vec{x} + \vec{y}) + \vec{z} &= a_1 + (b_1 + c_1)  + a_2x + (b_2x + c_2x) + a_3x^2 + (b_3x^2 + c_3x^2) && \text{Aplicando distrubutividad}\\ 
	(\vec{x} + \vec{y}) + \vec{z} &= \vec{x} + (\vec{y} + \vec{z}) && \text{Definiendo la suma en $ \Po $}\\ 
\end{align*}
\begin{center}
	$ \therefore \qquad $ la suma es asociativa en $ \Po $
\end{center}

Por demostrar: $ \vec{0} + \vec{x} = \vec{x} $. Proponemos $ \vec{0} = 0 + 0x + 0x^2 $. \\
Sea $ \vec{x} \in \V $, entonces $ \vec{x} $ es de la forma \[ \vec{x} = a_1 + a_2x + a_3x^2  \]
\begin{align*}
	\vec{0} + \vec{x} &=  (0 + 0x + 0x^2) + (a_1 + a_2x + a_3x^2 )  && \text{ Por definición de $ \vec{x}, \vec{0} $}\\
	\vec{0} + \vec{x} &=  (0 + a_1) + (0 + a_2)x + (0 + a_3)x^2 && \text{ Por definición de  + en $ \Po $}\\
	\vec{0} + \vec{x} &=  a_1 +  a_2x + a_3x^2 && \text{ Porque los elementos en $ \R $ tienen neutro aditivo}\\
	\vec{0} + \vec{x} &= \vec{x} && \text{ Por definición de $ \vec{x} $}
\end{align*}
\begin{center}
	$ \therefore   \qquad 0 + 0x + 0x^2 $ es el neutro adivito en $ \Po $
\end{center}

Sea $ \vec{x} \in \V $, por demostrar, existe $ \vec{y} \in V  \tq \vec{x} +  \vec{y} = \vec{0}$, sabemos que  los elementos de $ \V $ tienen la siguiente forma\[  \vec{x} = a_1 + a_2x + a_3x^2 \] proponemos \[ \vec{y} = -a_1 - a_2x - a_3x^2 \]
\begin{align*}
	\vec{x} +  \vec{y} &= (a_1 + a_2x + a_3x^2) + (-a_1 - a_2x - a_3x^2 )&& \text{Por definición de los vectores}\\
	\vec{x} +  \vec{y} &= (a_1 - a_1) + (a_2 - a_2)x + (a_3 - a_3)x^2&& \text{Por definición de la suma en $ \Po $}\\
	\vec{x} +  \vec{y} &= (0) + (0)x + (0)x^2&& \text{Los elementos del campo tienen inverso aditivo}\\
	\vec{x} +  \vec{y} &= \vec{0}&& \text{Por definición del neutro aditivo}
\end{align*}
\begin{center}
	$ \therefore \qquad -a_1 - a_2x - a_3x^2  $ es el inverso aditivo de $ \vec{x} $
\end{center}

Sea $ \vec{x}  \in \V $, por demostrar $ \vec{1} \* \vec{x} = \vec{x}$\\ Proponemos $ \vec{1} = 1 $
\begin{align*}
	1\* \vec{x} &= 1(a_1 + a_2x + a_3x^2) && \text{Por definición de los elementos de $ \Po $}\\
	1\* \vec{x} &= (1 \* a_1) + (1 \* a_2)x + (1 \* a_3)x^2 && \text{Por  definición del producto en $ \Po $}\\
	1\* \vec{x} &= a_1 + a_2x + a_3x^2 && \text{Puesto que los elementos del campo tienen neutro multiplicativo}\\
	1\* \vec{x} &= \vec{x}&& \text{Por la definición de $ \vec{x} $}\\
\end{align*}
\begin{center}
	$ \therefore \vec{1} $ es el neutro multiplicativo en $ \Po $
\end{center}

Sean $ \alpha, \beta \in \F( \F = \R) $ y $ \vec{x} \in \V $, por demostrar que $ (\alpha\beta)\vec{x} = \alpha(\beta\vec{x}) $
\begin{align*}
	(\alpha\beta)\vec{x} &= (\alpha\beta)(a_1 + a_2x + a_3x^2) && \text{Por definición de los elementos en $ \Po $}\\
	(\alpha\beta)\vec{x} &= ((\alpha\beta)a_1) + ((\alpha\beta)a_2)x + ((\alpha\beta)a_3)x^2 && \text{Por definición del producto en $ \Po $}\\
	(\alpha\beta)\vec{x} &= \alpha(\beta a_1) + \alpha(\beta a_2)x + \alpha (\beta a_3)x^2 && \text{Porque los elementos del campo asocian}\\
	(\alpha\beta)\vec{x} &= \alpha(\beta\vec{x}) && \text{Aplicando la definición del producto }\\
\end{align*}
\begin{center}
	$ \therefore \qquad $ en $ \Po $ se cumple que $ (\alpha\beta)\vec{x} = \alpha(\beta\vec{x}) $
\end{center}

Sean $ \alpha, \beta \in \F( \F = \R) $ y $ \vec{x} \in \V $, por demostrar que $ (\alpha + \beta)\vec{x} = \alpha\vec{x} + \beta\vec{x} $
\begin{align*}
	(\alpha + \beta)\vec{x} &= (\alpha + \beta)(a_1 + a_2x + a_3x^2) && \text{Definición de elementos en $ \Po $}\\
	(\alpha + \beta)\vec{x} &= \alpha a_1 + \beta a_1 + \alpha a_2x + \beta a_2x + \alpha a_3x^2 + \beta a_3x^2 && \text{Pues los elementos del campo tienen distributividad}\\
	(\alpha + \beta)\vec{x} &= \alpha a_1 + \alpha a_2x + \alpha a_3x^2 + \beta a_1  + \beta a_2x  + \beta a_3x^2 && \text{Reordenando}\\
	(\alpha + \beta)\vec{x} &= \alpha(a_1 + a_2x + a_3x^2) + \beta(a_1 + a_2x + a_3x^2)&& \text{Por definición del producto}\\
	(\alpha + \beta)\vec{x} &= \alpha\vec{x} + \beta\vec{x}&& \text{Por definición de los elementos en $ \Po $}\\
\end{align*}
\begin{center}
	$ \therefore \qquad  $ en $ \Po $ se cumple distributividad cuando un elemento se multiplica por la suma de dos escalares
\end{center}

Sea $ \alpha \in \V $, $ \vec{x}, \vec{y} \in \V $, por demostrar que $ \alpha(\vec{x} + \vec{y}) = \alpha\vec{x} + \alpha\vec{y}$
\begin{align*}
	\alpha(\vec{x} + \vec{y}) &= \alpha( (a_1 + a_2x + a_3x^2) + (b_1 + b_2x + b_3x^2) ) && \text{Por definición de los elementos en $ \Po $}\\
	\alpha(\vec{x} + \vec{y}) &= \alpha((a_1 + b_1) + (a_2 + b_2)x + (a_3 + b_3)x^2)&& \text{Por definición de la suma en $ \Po $}\\
	\alpha(\vec{x} + \vec{y}) &= \alpha(a_1 + b_1) + \alpha(a_2 + b_2)x + \alpha(a_3 + b_3)x^2&& \text{Por definición del producto en $ \Po $}\\
	\alpha(\vec{x} + \vec{y}) &= (\alpha a_1 + \alpha b_1) + (\alpha a_2 + \alpha b_2)x + (\alpha a_3 +\alpha b_3)x^2&& \text{Porque los elementos del campo tienen distributividad}\\
	\alpha(\vec{x} + \vec{y}) &= \alpha(a_1 + a_2x + a_3x^2) + \alpha(b_1 + b_2x + b_3x^2)&& \text{Agrupando de manera conveniente}\\
	\alpha(\vec{x} + \vec{y}) &= \alpha(\vec{x}) + \alpha(\vec{y})&& \text{Por definición de dichos elementos}\\
\end{align*}
\begin{center}
	$ \therefore \qquad $ en $ \Po $ se cumple que $ \alpha(\vec{x} + \vec{y}) = \alpha\vec{x} + \alpha\vec{y} $
\end{center}



\noindent2. Muestre que el conjunto  $\beta =  \{ 1, x , x^2 \}$ es base de $ \mathbb{P}_{2}(\mathbb{R})$
\begin{definition}
	Sea $ \mathcal{S} $ un subconjunto de un espacio vectorial $ \mathcal{V} $ decimos que $ \mathcal{S} $ genera a $ \mathcal{V} $ si $ \forall \hat{x} \in \mathcal{V} $ es una combinación lineal de elementos de $ \mathcal{S} $ a la generad de s se le denota como $ span(\mathcal{S}), <\mathcal{S}>, gen(\mathcal{S})$ 
\end{definition}

\begin{definition}
	Una \textbf{base} $ \beta $ de $ \V $ espacio vectorial es un subconjunto de $ \V \tq \beta$  genera a $ \V $ y $ \beta $ es linealmente independiente
\end{definition}


Diremos que el conjunto $ \beta $ genera a $ \Po$ si ocurre que 
\[ \alpha_1 (p_1(x)) + \alpha_2(p_2(x)) + \alpha_3(p_3(x)) = \beta_1 (1 + 0 x + 0x^2) + \beta_2(0 + 1x + 0x^2) + \beta_3( 0 + 0x + 1x^2) \]
donde $ p_1, p_2, p_2 \in \beta $ por lo que, sean $ \alpha_1, \alpha_2, \alpha_3 \in \R $
%NO hubo de otra mas que ponerlo de esta manera para que cupiera bien
\[ \alpha_1(1 + 0x +0x^2) + \alpha_2(0 +x + 0x^2) + \alpha_3(0 + 0x +x^2) = \beta_1(1 + 0x +0x^2) + \beta_2(0 +x + 0x^2) + \beta_3(0 + 0x +x^2) \]
\[ (\alpha_1 + 0\alpha_1x +0\alpha_1x^2) + (0\alpha_2 +x\alpha_2 + 0\alpha_2x^2) + (0\alpha_3 + 0\alpha_3x +\alpha_3x^2) = (\beta_1 + 0\beta_1x +0\beta_1x^2) + (0\beta_2 +\beta_2x + 0\beta_2x^2) + (0\beta_3 + 0\beta_3x +\beta_3x^2) \]
\[ (\alpha_1 + 0\alpha_2 + 0\alpha_3) + (0\alpha_1 + \alpha_2 + 0\alpha_3)x + (0\alpha_1 + 0\alpha_2 + \alpha_3)x^2 = (\beta_1 + 0\beta_2 + 0\beta_3) + (0\beta_1 + \beta_2 + 0\beta_3)x + (0\beta_1 + 0\beta_2 + \beta_3)x^2 \]


\begin{align*}
	\begin{pmatrix}
	\alpha_1 & 0\alpha_2 & 0\alpha_3 \\
	0\alpha_1 & \alpha_2 & 0\alpha_3 \\
	0\alpha_1 & 0\alpha_2 & \alpha_3 
	\end{pmatrix} 
	& = 
	\begin{pmatrix}
	\beta_1 & 0\beta_2 & 0\beta_3\\
	0\beta_1 & \beta_2 & 0\beta_3\\
	0\beta_1 & 0\beta_2 & \beta_3
	\end{pmatrix} && \text{Agrupando cada uno de los elementos en una matrix}\\
	\Iden & = \Iden && \text{Manteniendo sólo coeficientes}
\end{align*}
De esta manera ha quedado claro que dichos coeficientes $ \beta $ existen, es más, podemos afirmar que son: $$ \alpha_1 = \beta_1, \quad \alpha_2 = \beta_2, \quad \alpha_3 = \beta_3 $$
\begin{center}
 $ \therefore \qquad <\beta> = \Po$ 
\end{center}
Ahora veamos si $ \beta $ es linealmente independiente para lo que debe ocurrir
\begin{definition}
	Sea $ \mathds{S} $ un subconjunto de $ \V $ un espacio vectorial, decimos que $ \mathds{S} $ es linealmente independiente si la única solución para $ \alpha_1, \alpha_2 \dots \alpha_n \in \R $ \[ \alpha_1\vec{s}_1 + \alpha_2\vec{s}_2 + \dots + \alpha_n\vec{s}_n = 0 \] es que todos los coeficientes $ \alpha_i,  i \in \{ 1, 2, \dots, n \} $ sean todos 0
\end{definition}

Sean $ \alpha_1, \alpha_2, \alpha_3 \in \R $ 
\begin{align*}
	\alpha_1(1 + 0x + 0x^2) + \alpha_2(0 + x + 0x^2) + \alpha_3(0 + 0x + x^2) &= \vec{0} && \text{$ \beta $ como combinación lineal}\\
	\alpha_1(1 + 0x + 0x^2) + \alpha_2(0 + x + 0x^2) + \alpha_3(0 + 0x + x^2) &= 0 + 0x + 0x^2 && \text{Por definición de $ \vec{0} \in \Po $}\\
	(1\alpha_1 + 0\alpha_1x + 0\alpha_1x^2) + (0\alpha_2 + \alpha_2x + 0\alpha_2x^2) + (0\alpha_3 + 0\alpha_3x + \alpha_3x^2) &= 0 + 0x + 0x^2  && \text{Distribuyendo}\\
	(\alpha_1 + 0\alpha_2 + 0\alpha_3) + (0\alpha_1 + \alpha_2 + 0\alpha_3)x + (0\alpha_1 + 0\alpha_2 + \alpha_3)x^2 &= 0 + 0x + 0x^2 && \text{Agrupando}
\end{align*}
Finalmente igualemos entrada con entrada
\begin{align*}
	\begin{pmatrix}
	\alpha_1 & 0\alpha_2 & 0\alpha_3\\
	0\alpha_1 & \alpha_2 & 0\alpha_3\\
	0\alpha_1 & 0\alpha_2 & \alpha_3 
	\end{pmatrix} 
	& = \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Igualemos entrada por entrada}\\
	\Iden & = \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Mateniendo sólo coeficientes}
\end{align*}
Finalmente es fácil observar que 
\[ \alpha_1 = \alpha_2 = \alpha_3 = 0  \]
\begin{center}
	$ \therefore \qquad \beta$ es linealmente independiente\\
	$ \therefore \qquad \beta$ es base para $ \Po $
\end{center}
\noindent3. Muestre que la siguiente transformación es lineal.
 $$    T \colon  \mathbb{P}_{2}(\mathbb{R})  \longrightarrow \mathbb{P}_{2}(\mathbb{R}) $$
	$$ T(f(x)) \mapsto  xf^{'}(x) +x f(2) + f(3)$$
Como el dominio de $ T $ es $ \Po $, entonces sean $ p(x), q(x) \in \Po $, y $ \xi \in \R $ recordemos que los elementos de $ \Po $ tienen la forma
\begin{align*}
	p(x) & =\alpha_1 + \alpha_2x + \alpha_3x^2\\
	q(x) & =\delta_1 + \delta_2x + \delta_3x^2
\end{align*}
\begin{align*}
	\xi p(x) + q(x) &= \xi (\alpha_1 + \alpha_2x + \alpha_3x^2) + (\delta_1 + \delta_2x + \delta_3x^2) && \text{Por definición de $ p(x), q(x)$}\\
	\xi p(x) + q(x) &=  (\xi \alpha_1 + \xi\alpha_2x + \xi\alpha_3x^2) + (\delta_1 + \delta_2x + \delta_3x^2) && \text{Distribuyendo $ \xi $}\\
	\xi p(x) + q(x) &=  (\xi \alpha_1 + \delta_1) + (\xi\alpha_2 + \delta_2) x + (\xi\alpha_3 + \delta_3)x^2 && \text{Por definición  de la suma en $ \Po $}
\end{align*}
\begin{align*}
	T(\xi p(x) + q(x)) &= \xi\alpha_2 + \delta_2 + 2x(\xi\alpha_3 + \delta_3) + x((\xi \alpha_1 + \delta_1) + 2(\xi\alpha_2 + \delta_2) + 4(\xi\alpha_3 + \delta_3)) + ((\xi \alpha_1 + \delta_1) + 3(\xi\alpha_2 + \delta_2) + 9(\xi\alpha_3 + \delta_3))\\
	&= \xi\alpha_2 + \delta_2 + 2x(\xi\alpha_3 + \delta_3) + x(\xi \alpha_1 + \delta_1) + 2x(\xi\alpha_2 + \delta_2) + 4x(\xi\alpha_3 + \delta_3) + (\xi \alpha_1 + \delta_1) + 3(\xi\alpha_2 + \delta_2) + 9(\xi\alpha_3 + \delta_3)\\
	& = (\xi \alpha_1 + \delta_1) + 3(\alpha_2 + \delta_2) + 9 (\xi \alpha_3 + \delta_3) + x(\xi\alpha_1 + \delta_1 + 3 \xi\alpha_2 + 3 \delta_2 + 4\xi\alpha_3 + 4\delta_3) + 2x^2(\xi\alpha_3 + \delta_3)\\
	&= \xi \left( \alpha_1 + 3\alpha_2 + 9\alpha_3 + x(\alpha_1 + 3 \alpha_2 + 4 \alpha_3) + 2x^2\alpha_3 \right)+ \delta_1 + 3\delta_2 + 9\delta_3 + x (\delta_1 + 3\delta_2 + 4\delta_3) + 2x^2\delta_3\\
	&= \xi T(p(x))+ T(q(x))\\
\end{align*}
\begin{center}
	$ \therefore \qquad T $ es transformación lineal, pues hemos visto que abre sumas <<$ p(x) + q(x) $>> y saca escalares <<$ \xi $>>
\end{center}\newpage
\noindent4. Determine el núcleo y la imagen de $T$.\\
\begin{definition}
	Sea $ T: V \rightarrow W $ una transformación lineal, la \textbf{imagen} de una trasformación $ T $ es $Im(T) = \left\lbrace T(\hat{x}) | \hat{x} \in V  \right\rbrace$
\end{definition}
\begin{definition}
	Sea $ T: V \rightarrow W $ una transformación lineal, el \textbf{núcleo} de una trasformación $ T $ es $Nu(T) = \left\lbrace \hat{x} \in V | T(\hat{x}) = \hat{0}_{W}  \right\rbrace$
\end{definition}
Para ello, tomemos un elemento en el dominio de $ T $. Sea $ p(x) \in \Po \tq p(x) = \eta_1 + \eta_2x + \eta_3x^2 $ y $ \vec{0}_{\Po} $
\begin{align*}
	T(p(x)) &= \vec{0}_{\Po} && \text{Por definición del núcleo}\\
	T(\eta_1 + \eta_2x + \eta_3x^2) &= 0 + 0x + 0x^2 && \text{Por definición de los elementos}\\
	\eta_1 + 3\eta_2 + 9\eta_3 + x(\eta_1 + 3 \eta_2 + 4 \eta_3) + 2 x^2\eta_3 &= 0 + 0x + 0x^2 && \text{Siguiendo la regla de correspondencia}\\
	\\
	\eta_1 + 3\eta_2 + 9\eta_3  &= 0 && \text{Igualando entrada a entrada}\\
	x(\eta_1 + 3 \eta_2 + 4 \eta_3) &= 0x&& \text{Igualando entrada a entrada}\\
	2 x^2\eta_3 &= 0x^2 && \text{Igualando entrada a entrada}\\
	\\
	\eta_3 &= 0 && \text{De lo anterior}\\
	\eta_1 + 3\eta_2 + 9(0) &= 0 && \text{Sistituyendo}\\
	\eta_1  &= - 3\eta_2 && \text{Sistituyendo}\\
\end{align*}
\begin{center}
	La solución puede escribirse como $ (-3 + 1x + 0x^2 ) \eta_2 $ por lo que el \textbf{núcleo} de la transformación $ \{(-3(\eta_2) + x(\eta_2) + 0x^2)\} $. Cabe mencionar que la nulidad de $ T $ es 1, pues esa es la dimensión del núcleo y además, $ T $ no es una transformación uno a uno pues el núcleo $ \neq \vec{0}_{\Po} $
\end{center}

Para ver cuál es la imagen de la transformación lineal tomemos un elemento arbitrario en el dominio y otro en su imagen. Sean $ p(x), q(x) \in \Po $, recordemos que los elementos de $ \Po $ tienen la forma
\begin{align*}
p(x) & =\alpha_1 + \alpha_2x + \alpha_3x^2\\
q(x) & =\delta_1 + \delta_2x + \delta_3x^2
\end{align*}

\begin{align*}
	T(p(x)) &= q(x) && \text{Por definición de la imagen}\\
	T(\alpha_1 + \alpha_2x + \alpha_3x^2) &= \delta_1 + \delta_2x + \delta_3x^2 && \text{Por definición delos vectores}\\
	 \eta_1 + 3\eta_2 + 9\eta_3 + x(\eta_1 + 3 \eta_2 + 4 \eta_3) + 2 x^2\eta_3 &= \delta_1 + \delta_2x + \delta_3x^2 && \text{Por definición delos vectores}\\
	 \\
	 \eta_1 + 3\eta_2 + 9\eta_3 &= \delta_1 && \text{Igualando entrada a entrada}\\
	x(\eta_1 + 3 \eta_2 + 4 \eta_3) &= \delta_2x  && \text{Igualando segunda enterada}\\
	2x^2\eta_3 &= \delta_3x^2 && \text{Igualando tercera entrada}\\
	 \\
	 \eta_1 + 3\eta_2 + 9\eta_3 &= \delta_1 && \text{Igualando entrada a entrada}\\
	\eta_1 + 3 \eta_2 + 4 \eta_3 &= \delta_2 && \text{Por el inverso multiplicativo de $ x $}\\
	2\eta_3 &= \delta_3 && \text{Por el inverso multiplicativo de $ x^2 $}\\
\end{align*}
\begin{center}
	$ \therefore \qquad $ los elementos de la imagen son de la forma $ q(x) = \delta_1 + \delta_2x + \delta_3x^2 $ donde 
	\begin{align*}
	\delta_1 &= \eta_1 + 3\eta_2 + 9\eta_3 \\
	\delta_2 &= \eta_1 + 3 \eta_2 + 4 \eta_3 \\
	\delta_3  &= 2\eta_3 
	\end{align*}
Es decir, todo $ \Po $
\end{center}

\noindent5. Encuentre la matriz asociada a $T$ con respecto a la base $\beta$, esto es $[T]_{\beta}$.
Tomememos las bases ordenadas $ \beta\{ 1,x,x^2 \} $ y $ \gamma = \{ 1, x, x^2 \} $ entonces. Apliquemosla trasformación $ T $ a cada uno de los elementos de $ \beta $
\begin{align*}
	 T(p(x)) &= \eta_1 + 3\eta_2 + 9\eta_3 + x(\eta_1 + 3 \eta_2 + 4 \eta_3) + 2 x^2\eta_3 && \text{Por el ejercicio anterior}\\
	 T(1) &= 1 + 3(0) + 9(0) + x(1 + 3 (0) + 4 (0)) + 2 x^2(0) && \text{Porque }\eta_1 = 1, \eta_2 = 0, \eta_3 = 0 \\
	 T(1) &= 1 + x && \text{Operando }\\
	 \\
	 T(x) &= (0) + 3(1) + 9(0) + x((0) + 3 (1) + 4 (0)) + 2 x^2(0) && \text{Porque }\eta_1 = 0, \eta_2 = 1, \eta_3 = 0 \\
	 T(x) &= 3 + 3x && \text{Operando }\\
	 \\
	 T(x^2) &= (0) + 3(0) + 9(1) + x((0) + 3 (0) + 4 (1)) + 2 x^2(1) && \text{Operando }\\
	 T(x^2) &= 9+ 4x + 2x^2 && \text{Desarrollando }\\
\end{align*}
\begin{align*}
	T(1) &= 1\* 1 + 1\*x + 0\*x^2 && \text{Igualemos el primer elemento de $ \beta $}\\
	T(x) &=1\* 1 + 1\*x + 0\*x^2 && \text{Igualemos el segundo elemento de $ \beta $}\\
	T(x^2) &= 9\* 1 + 4\*x + 2\*x^2 && \text{Igualemos el tercer elemento de $ \beta $}\\
\end{align*}
De lo anterior, es claro poder concluir que 
\[ [T]_{\beta} = \T \]



\noindent6. ¿Cuál es el rango de $[T]_{\beta}$?\\
El rango de una matriz es el número de columnas linealmente independientes, en este paso es muy claro que sólo tiene 2 columnas linealmente independientes, por lo que su rango es $ n = 2 $\\


\noindent7. La matriz $[T]_{\beta}$ es invertible, si sí muéstrelo, si no argumente porque.\\
Como vimos en clase, una matriz es invertible si y sólo si tiene rango completo, en ese caso no fue así, por lo que $ [T]_{\beta} $ no es invertible\\


\noindent8. ¿Cuales son los valores propios asociados a $[T]_{\beta}$?
\begin{definition}
	Sea $ T $ un operador lineal sobre $V$, dónde $V$ es de dimensión finita y $\vec{x}\in V$ tal que $\vec{x}$ no es 0. 
	Sean $A\in M_{n*n}(\mathbb{R})$, entonces $\lambda$ es un valor propio de A si y sólo si $det(A-\lambda Id_{n})=0$
\end{definition}

Por lo que comencemos calculando el $ det([T]_{\beta} - \lambda Id_n) $
\begin{align*}
	det\left([T]_\beta - \lambda Id_3 \right) &= 0 && \text{Por definición de valores propios}\\
	det\left([T]_\beta - \lambda\Iden \right) &= 0 && \text{Por definición de la identidad}\\
	det\left(\T - \lambda\Iden \right) &= 0 && \text{Por lo obtenido en $ [T]_\beta $}\\
	det\left(\T - \begin{pmatrix}
	\lambda & 0 & 0\\
	0 & \lambda & 0\\
	0 & 0 & \lambda
	\end{pmatrix} \right) &= 0 && \text{Multiplicación por un escalar}\\
	det \begin{pmatrix}
	1- \lambda & 3 & 9\\
	1 & 3 -\lambda & 4\\
	0 & 0 & 2- \lambda 
	\end{pmatrix} &= 0 && \text{Por suma de matrices}\\
\end{align*}

\begin{definition}
	Sea $ A \in M_{2x2}(\R) \tq A = \begin{pmatrix}
	a& b\\
	c& d
	\end{pmatrix}$ Entonces el determinante de A está definido como $  det(A) = ad -bc $
\end{definition}
	\begin{definition}
	Sea $ A \in M_{nxn}(\F) $  si $ n < 1 $ entonces $ A = (A_{11}) $ entonces $ det(A) = A_{11} $ para $ n\geq 2 $ definimos el determinante de manera recursiva como
	\[ det(A) = \sum_{j = 1}^{n (dimen.)} (-1)^{1 + j} A_{1j}det(\hat{A}_{1j}) \]
\end{definition}

Por lo que el  $ 	det \begin{pmatrix}
1- \lambda & 3 & 9\\
1 & 3 -\lambda & 4\\
0 & 0 & 2- \lambda 
\end{pmatrix} $ se calcula como sigue

\begin{align*}
(1- \lambda)det(\hat{A}_{11}) - 3det\hat{A}_{12} + 9det\hat{A}_{13} &= 0 && \text{Por lo definido anteriormente}^{(**)}\\
\\
det(\hat{A}_{11}) & = (a_{22})(a_{33}) - (a_{32})(a_{23})  && \text{Por definición del determinante en 2x2}\\
det\begin{pmatrix}
3 - \lambda & 4\\
0 & 2 - \lambda
\end{pmatrix} & = (3 - \lambda) ( 2- \lambda) - 4(0) && \text{Calculando el determinante del menor}\\
det(\hat{A}_{11})& = (3 - \lambda) ( 2-\lambda) && \text{Operando}\\
\\
det(\hat{A}_{12}) & = (a_{12})(a_{33}) - (a_{32})(a_{13})  && \text{Por definición de determinante en 2x2}\\
det\begin{pmatrix}
1 & 4 \\
0 & 2-\lambda \\
\end{pmatrix}  &= (2- \lambda)- 0 && \text{Calculando el determinante del menor}\\
det(\hat{A}_{12}) & = 2-\lambda  && \text{Operando}\\
\\
det(\hat{A}_{13}) & = (a_{12})(a_{23}) - (a_{22})(a_{13})  && \text{Por definición de determinante en 2x2}\\
det\begin{pmatrix}
1 & 3 - \lambda\\
0 & 0\\
\end{pmatrix} & = (a_{12})(a_{23}) - (a_{22})(a_{13})  && \text{Calculando el determinante del menor}\\
det(\hat{A}_{13}) & = 0 && \text{Operando}
\end{align*}
Luego, por $ (**) $ tenemos que $$ det([T]_{\beta} - \lambda Id_n) = (1-\lambda)(3-\lambda)(2-\lambda) - 3(2-\lambda) = 0 $$  
De lo anterior obtenemos la siguiente equación con 3 incógnitas
\begin{align*}
	(1-\lambda)(3-\lambda)(2-\lambda) - 3(2-\lambda) &= 0 && \text{Por la definición de determinante}\\
	(3-\lambda-3\lambda+\lambda^2)(2-\lambda) - 3(2-\lambda) &= 0 && \text{Operando los primeros miembros}\\
	6-2\lambda-6\lambda+2\lambda^2-3\lambda+\lambda^2+3\lambda^2-\lambda^3 -6+3\lambda &= 0 && \text{Desarrolando }\\
	-\lambda^3 + 6 \lambda^2 - 8\lambda&= 0 && \text{Agrupando términos semejantes }\\
	-\lambda  ( \lambda^2 - 6 \lambda + 8)&= 0 && \text{Factorizando } \lambda\\
	-\lambda  ( \lambda-2)(\lambda-4)&= 0 && \text{Factorizando el trinomio }\\
\end{align*}
\begin{center}
	$ \therefore  $ las soluciones a la ecuación son 
	\begin{align*}
		\lambda_1 &= 4\\
		\lambda_2 &= 2\\
		\lambda_3 &= 0
	\end{align*} esos mismos son los valores propios asociados a $ [T]_\beta = \T $
\end{center}
\noindent9. Determine los vectores propios asociados a cada valor propio. 
\begin{definition}
	Decimos que $\vec{x}$ es vector propio de T si $T(\vec{x})= \lambda\vec{x}$ donde $\lambda\in \mathbb{R}$.
\end{definition}

Para eso tomemos $ \lambda_1 = 4 $ y sustituyamos en $ \begin{pmatrix}
1- \lambda & 3 & 9\\
1 & 3 -\lambda & 4\\
0 & 0 & 2- \lambda 
\end{pmatrix} $

\begin{align*}
	\begin{pmatrix}
	1- \lambda & 3 & 9\\
	1 & 3 -\lambda & 4\\
	0 & 0 & 2- \lambda 
	\end{pmatrix} \* \begin{pmatrix}
	x_1\\
	x_3\\
	x_3
	\end{pmatrix} &= \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Por la definición de vector propio}\\ 
	%%%%%%
	\begin{pmatrix}
	1- (4) & 3 & 9\\
	1 & 3 -(4) & 4\\
	0 & 0 & 2- (4) 
	\end{pmatrix} \* \begin{pmatrix}
	x_1\\
	x_3\\
	x_3
	\end{pmatrix} &= \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Porque tomamos $ \lambda_1 = 4 $}\\
	%%%%%%
	\begin{pmatrix}
	-3 & 3 & 9\\
	1 & -1 & 4\\
	0 & 0 & - 2 
	\end{pmatrix} \* \begin{pmatrix}
	x_1\\
	x_3\\
	x_3
	\end{pmatrix} &= \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Operando los signos}\\
\end{align*}
De lo anterior obtenemos el siguiente sistema de ecuaciones
\begin{align}
	-3x_1 + 3x_2 + 9x_3 &= 0\\
	x_1 -x_2 +4x_3 &= 0\\
	-2x_3 &= 0
\end{align}
Por lo que es fácil deducir que $ x_3 = 0 $ y si lo sustituimos en 2, tenemos que $ x_2 = x_3 $
por lo que \[ \vec{v}_1 = \begin{pmatrix}
1\\
1\\
0
\end{pmatrix} \]
%%%%%%%% nuevo vector %%%%%%%%
Para eso tomemos $ \lambda_2 = 2 $ y sustituyamos en $ \begin{pmatrix}
1- \lambda & 3 & 9\\
1 & 3 -\lambda & 4\\
0 & 0 & 2- \lambda 
\end{pmatrix} $

\begin{align*}
	\begin{pmatrix}
	1- \lambda & 3 & 9\\
	1 & 3 -\lambda & 4\\
	0 & 0 & 2- \lambda 
	\end{pmatrix} \* \begin{pmatrix}
	x_1\\
	x_3\\
	x_3
	\end{pmatrix} &= \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Por la definición de vector propio}\\ 
	%%%%%%
	\begin{pmatrix}
	1- (2) & 3 & 9\\
	1 & 3 -(2) & 4\\
	0 & 0 & 2- (2) 
	\end{pmatrix} \* \begin{pmatrix}
	x_1\\
	x_3\\
	x_3
	\end{pmatrix} &= \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Porque tomamos $ \lambda_2 = 2 $}\\
	%%%%%%
	\begin{pmatrix}
	-1 & 3 & 9\\
	1 & 1 & 4\\
	0 & 0 &  0 
	\end{pmatrix} \* \begin{pmatrix}
	x_1\\
	x_3\\
	x_3
	\end{pmatrix} &= \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Operando los signos}\\
\end{align*}
De lo anterior obtenemos el siguiente sistema de ecuaciones
\begin{align}
	-1x_1 + 3x_2 + 9x_3 &= 0\\
	x_1 +x_2 +4x_3 &= 0
\end{align}
Por lo que es fácil deducir que $ x_1 =- \dfrac{3}{4}x_3 $, al sumar ambas equaciones y si lo sustituimos en 5, tenemos que $ x_2 = \dfrac{-13}{4}x_3 $, para el vector tomemos $ x_3 = 4 $
por lo que \[ \vec{v}_2 = \begin{pmatrix}
-3\\
-13\\
4
\end{pmatrix} \]
%%%%%%%% nuevo vector %%%%%%%%
Para eso tomemos $ \lambda_3 = 0 $ y sustituyamos en $ \begin{pmatrix}
1- \lambda & 3 & 9\\
1 & 3 -\lambda & 4\\
0 & 0 & 2- \lambda 
\end{pmatrix} $

\begin{align*}
	\begin{pmatrix}
	1- \lambda & 3 & 9\\
	1 & 3 -\lambda & 4\\
	0 & 0 & 2- \lambda 
	\end{pmatrix} \* \begin{pmatrix}
	x_1\\
	x_3\\
	x_3
	\end{pmatrix} &= \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Por la definición de vector propio}\\ 
	%%%%%%
	\begin{pmatrix}
	1- (0) & 3 & 9\\
	1 & 3 -(0) & 4\\
	0 & 0 & 2- (0) 
	\end{pmatrix} \* \begin{pmatrix}
	x_1\\
	x_3\\
	x_3
	\end{pmatrix} &= \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Porque tomamos $ \lambda_3 = 0 $}\\
	%%%%%%
	\begin{pmatrix}
	1 & 3 & 9\\
	1 & 3 & 4\\
	0 & 0 & 2 
	\end{pmatrix} \* \begin{pmatrix}
	x_1\\
	x_3\\
	x_3
	\end{pmatrix} &= \begin{pmatrix}
	0\\
	0\\
	0
	\end{pmatrix} && \text{Operando los signos}\\
\end{align*}
De lo anterior obtenemos el siguiente sistema de ecuaciones
\begin{align}
	x_1 + 3x_2 + 9x_3 &= 0\\
	x_1 + 3x_2 +4x_3 &= 0\\
	2x_3 &= 0
\end{align}
Por lo que es fácil deducir que $ x_3 = 0 $, al sustituirlo en 7, tenemos que $ x_1 = -3x_2$ tomemos $ x_2 = 1 $
por lo que \[ \vec{v}_3 = \begin{pmatrix}
-3\\
1\\
0
\end{pmatrix} \]
Así, podemos obtener \[ Q = \begin{pmatrix}
1 & -3 & -3\\
1 & -13 & 1\\
0 & 4 & 0\\
\end{pmatrix}\]

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent10. Muestre que el conjunto de los vectores propios es una base ordenada.

\begin{definition}
	Sea $ \V $ un espacio vectorial dimensionalmente finito. Una base ordenada para $ \V $ es una base para $ \V $ establecida con un orden específico; es decir, una base ordenada para $ \V $ en una secuencia finita de elementos de $ \V $ linealmente independientes que generan a $ \V $
\end{definition}
Nombremos $ \gamma = \left\lbrace \begin{pmatrix}
1\\
1\\
0
\end{pmatrix}, \begin{pmatrix}
-3\\
-13\\
4
\end{pmatrix}, \begin{pmatrix}
-3\\
1\\
0
\end{pmatrix} \right\rbrace $,  que también se puede expresar como $ \gamma = \{ 1 +x, -3 -13x +4x^2, -3 + x \} $
Veamos quién es la generada de $ \gamma $. Sean $ \alpha_1, \alpha_2, \alpha_3 \in \R $ y $ \beta_1, \beta_2, \beta_3 \in \R $ entonces planteemos, y reorganicemos con los términos semejantes
\begin{align*}
	\alpha_1(1+x + 0x^2) + \alpha_2(-3-13x+4x^2) + \alpha_3(-3 +x + 0x^2) & = \beta_1(1 + 0x + 0x^2) + \beta_2( 0 + x + 0x^2) + \beta_3(0 + 0x + x^2)\\
	(\alpha_1 - 3\alpha_2 - 3\alpha_3) + (\alpha_1 - 13 \alpha_2 + \alpha_3)x  + (0\alpha_1 + 4\alpha_2 + 0\alpha_3)x^2& = (\beta_1 + 0 \beta_2 + 0\beta_3) + (0\beta_1 + \beta_2 + 0\beta_3)x + (0\beta_1 + 0 \beta_2 + \beta_3)x^2
\end{align*}
\begin{align*}
	\alpha_1 - 3\alpha_2 - 3\alpha_3  & = \beta_1 + 0 \beta_2 + 0\beta_3\\ 
	\alpha_1 - 13 \alpha_2 + \alpha_3 & = 0\beta_1 + \beta_2 + 0\beta_3\\ 
	0\alpha_1 + 4\alpha_2 + 0\alpha_3 & = 0\beta_1 + 0 \beta_2 + \beta_3
\end{align*}
Ahora sólo mantengamos los coeficientes y resolvamos por el método\textit{ Gauss-Jordan}
\begin{align*}
	\begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	1 & -13 & 1 & 0 & 1 & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix} & = \begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & -10 & 1 & -1 & 1 & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix}&& \text{ 1a Fila $ \* $ -1 + 2a Fila en 2aFila }\\
\end{align*}
\begin{align*}
	\begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & -10 & 1 & -1 & 1 & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix} &= \begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & 1 & -\frac{2}{5} & \frac{1}{10} & -\frac{1}{10} & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix}&& \text{ 2a Fila $ \* -\frac{1}{10}$ }\\
\begin{pmatrix}[ccc|ccc]
1 & -3 & -3 & 1 & 0 & 0\\
0 & 1 & -\frac{2}{5} & \frac{1}{10} & -\frac{1}{10} & 0\\
0 & 4 & 0 & 0 & 0 & 1
\end{pmatrix}& = \begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & 1 & -\frac{2}{5} & \frac{1}{10} & -\frac{1}{10} & 0\\
	0 & 0 & \frac{8}{5} & -\frac{2}{5} & \frac{2}{5} & 1
	\end{pmatrix} && \text{ 2a Fila $ \* -4$ + 3a Fila en 3a Fila }\\
	\begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & 1 & -\frac{2}{5} & \frac{1}{10} & -\frac{1}{10} & 0\\
	0 & 0 & \frac{8}{5} & -\frac{2}{5} & \frac{2}{5} & 1
	\end{pmatrix}  &= \begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & 1 & -\frac{2}{5} & \frac{1}{10} & -\frac{1}{10} & 0\\
	0 & 0 & 1 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix} && \text{ 3a Fila $ \* \frac{5}{8}$}\\
	\begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & 1 & -\frac{2}{5} & \frac{1}{10} & -\frac{1}{10} & 0\\
	0 & 0 & 1 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix} &= \begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & 1 & 0 & 0 & 0 & \frac{1}{4}\\
	0 & 0 & 1 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix} && \text{ 3a Fila $ \* \frac{2}{5}$ + 2a Fila en 2a Fila}\\
	\begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & 1 & 0 & 0 & 0 & \frac{1}{4}\\
	0 & 0 & 1 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix} &= \begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & 1 & 0 & 0 & 0 & \frac{1}{4}\\
	0 & 0 & 1 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix} && \text{ 3a Fila $ \* \frac{2}{5}$ + 2a Fila en 2a Fila}\\
	\begin{pmatrix}[ccc|ccc]
	1 & -3 & -3 & 1 & 0 & 0\\
	0 & 1 & 0 & 0 & 0 & \frac{1}{4}\\
	0 & 0 & 1 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix} & = \begin{pmatrix}[ccc|ccc]
	1 & -3 & 0 & \frac{1}{4} &\frac{3}{4} & \frac{15}{8} \\
	0 & 1 & 0 & 0 & 0 & \frac{1}{4}\\
	0 & 0 & 1 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix} && \text{ 3a Fila $ \* 3 + $  3a Fila en 3a Fila}\\
	\begin{pmatrix}[ccc|ccc]
	1 & -3 & 0 & \frac{1}{4} &\frac{3}{4} & \frac{15}{8} \\
	0 & 1 & 0 & 0 & 0 & \frac{1}{4}\\
	0 & 0 & 1 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix} & = \begin{pmatrix}[ccc|ccc]
	1 & 0 & 0 & \frac{1}{4} &\frac{3}{4} & \frac{21}{8} \\
	0 & 1 & 0 & 0 & 0 & \frac{1}{4}\\
	0 & 0 & 1 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix}&& \text{ 2a Fila $ \* 3 + $  1a Fila en 1a Fila}\\
\end{align*}
De esta manera hemos obtenido los coeficientes $ \alpha_1, \alpha_2, \alpha_3 $, veamos la sutileza al calcularlos pues encontramos $ Q^{-1} $
\begin{center}
	$ \therefore \qquad <\gamma> = \Po $
\end{center}
Por lo anterior, ya hemos encontrado $ Q^{-1} $ y esto sólo ocurre si la matriz es de rango completo, así que podemos afirmar que el rango de $ Q $ es 3, luego resulta sencillo observar que es linealmente independiente, desde su construcción.\\


Por otra parte, si comparamos $ \gamma $ con $ \beta' $ del ejercicio 12, veremos que ambas son bases pero no son las mismas bases ordenadas pues en $ \gamma $ se describe un orden distinto. 
\begin{center}
	$ \therefore \qquad \gamma$  es una base ordenada
\end{center}

%%%%%%%%%%%%
\noindent11. Determine $Q \in M_{3\times 3}(\mathbb{R})$, tal que $Q^{-1}[T]_{\beta} Q = D$, donde $D$ es una matriz diagonal cuyos elementos de la diagonal son valores propios.


Por el inciso anterior, podemos rescatar que $$ Q^{-1} = \begin{pmatrix}[ccr]
\frac{1}{4} &\frac{3}{4} & \frac{21}{8} \\
0 & 0 & \frac{1}{4}\\
-\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
\end{pmatrix} $$
Y por el ejercicio 9 tenemos que \[  Q = \begin{pmatrix}
1 & -3 & -3\\
1 & -13 & 1\\
0 & 4 & 0\\
\end{pmatrix}  \] y del ejercicio 5 concluimos que \[ [T]_\beta = \T \] Por lo que sólo resta calcular
\begin{align*}
	\left( \begin{pmatrix}[ccr]
	\frac{1}{4} &\frac{3}{4} & \frac{21}{8} \\
	0 & 0 & \frac{1}{4}\\
	-\frac{1}{4} & \frac{1}{4} & \frac{5}{8}
	\end{pmatrix} \* \T \right) \* \begin{pmatrix}
	1 & -3 & -3\\
	1 & -13 & 1\\
	0 & 4 & 0\\
	\end{pmatrix} &= \begin{pmatrix}
	1 & 3 & \frac{21}{2}\\
	0 & 0 & \frac{1}{2}\\
	0 & 0 & 0\\
	\end{pmatrix} \* \begin{pmatrix}
	1 & -3 & -3\\
	1 & -13 & 1\\
	0 & 4 & 0\\
	\end{pmatrix} \\
	\begin{pmatrix}
	1 & 3 & \frac{21}{2}\\
	0 & 0 & \frac{1}{2}\\
	0 & 0 & 0\\
	\end{pmatrix} \* \begin{pmatrix}
	1 & -3 & -3\\
	1 & -13 & 1\\
	0 & 4 & 0\\
	\end{pmatrix} & = \begin{pmatrix}
	4 & 0 & 0\\
	0 & 2 & 0\\
	0 & 0 & 0\\
	\end{pmatrix}
\end{align*}

\begin{center}
Finalmente veamos que $ \lambda_1 = 4, \lambda_2 = 3, \lambda_3 = 0 $ y efectivamente, son los elementos de la diagonal
\end{center}

%%%%%%%%%%%%5
\noindent12. Muestre que $\beta^{'} =\{ -3+x , -3-13x + 4x^2, 1+x \}$, es una base para $ \mathbb{P}_{2}(\mathbb{R})$ y además determine $[T]_{\beta^{'}}$ \\ \\
Primero veamos quién es la generada de $ \beta' $, para lo que tomemos elementos elementos aleatorios del campo y veamos a los  elementos de $ \beta' $ como combinación lineal. \\
Sean $ \alpha, \alpha_2, \alpha_3 \in \R $
\begin{align*}
	\alpha_1(-3 +x) + \alpha_2(-3 -13x + 4x^2) + \alpha_2(1+x) &= \beta_1(1 + 0x +0x^2) + \beta_2(0 + x + 0x^2) + \beta_3(0 + 0x + x^2)\\
	\alpha_1(-3 +x + 0x^2) + \alpha_2(-3 -13x + 4x^2) + \alpha_2(1+x + 0x^2) &= \beta_1(1 + 0x +0x^2) + \beta_2(0 + x + 0x^2) + \beta_3(0 + 0x + x^2)\\
	(-3\alpha_1 - 3\alpha_2 + \alpha_3) + (\alpha_1 -13 \alpha_2 +
	\alpha_3)x +(0\alpha_1 + 4 \alpha_2 + 0\alpha_3)x^2 &= (\beta_1 + 0\beta_2 + 0\beta_3) + (0\beta_1 + \beta_2 + 0\beta_3)x + (0\beta_1 + \beta_2 + \beta_3)x^2\\
	\\
	-3\alpha_1 - 3\alpha_2 + \alpha_3 &= \beta_1 + 0\beta_2 + 0\beta_3\\
	\alpha_1 -13 \alpha_2 +
	\alpha_3 & =0\beta_1 + \beta_2 + 0\beta_3\\
	0\alpha_1 + 4 \alpha_2 + 0\alpha_3 &= 0\beta_1 + \beta_2 + \beta_3
\end{align*}
luego, resolvamos el sistema de equaciones anterior, adjuntando la identidad y reduciéndola a su forma escalonada

\begin{align*}
	\begin{pmatrix}[ccc|ccc]
	-3 & -3 & 1 & 1 & 0 & 0\\
	1 & -13 & 1 & 0 & 1 & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix} &= \begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	1 & -13 & 1 & 0 & 1 & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix} && \text{1a fila } \* -\frac{1}{3}\\
	%%%%%%%%%%%%%% 2da operacion %%%%%%%%%%%%%
	\begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	1 & -13 & 1 & 0 & 1 & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix} &= \begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & -14 & \frac{4}{3} & \frac{1}{3} & 1 & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix} && \text{1a fila $ \* -1 + 2^a$ Fila en 2a fila }\\
	%%%%%%%%% 3a operación %%%%%%%%
	\begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & -14 & \frac{4}{3} & \frac{1}{3} & 1 & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix} &= \begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & 1 & -\frac{2}{21} & -\frac{1}{42} & -\frac{1}{14} & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix} && \text{2a fila } \* - \frac{1}{14}\\
	%%%%%%%%% 4a operacion 
	\begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & 1 & -\frac{2}{21} & -\frac{1}{42} & -\frac{1}{14} & 0\\
	0 & 4 & 0 & 0 & 0 & 1
	\end{pmatrix}  &= \begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & 1 & -\frac{2}{21} & -\frac{1}{42} & -\frac{1}{14} & 0\\
	0 & 0 & \frac{8}{21} & \frac{2}{21} & \frac{2}{7} & 1
	\end{pmatrix}  && \text{2a fila $ \* -4 $ + 3a fila en 3a fila } \\
	%%%%%%%%% 5a opreracion %%%%%%%%%
	\begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & 1 & -\frac{2}{21} & -\frac{1}{42} & -\frac{1}{14} & 0\\
	0 & 0 & \frac{8}{21} & \frac{2}{21} & \frac{2}{7} & 1
	\end{pmatrix}  & = \begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & 1 & -\frac{2}{21} & -\frac{1}{42} & -\frac{1}{14} & 0\\
	0 & 0 & 1 & \frac{1}{4} & \frac{3}{4} & \frac{21}{8}
	\end{pmatrix}  && \text{3a fila } \* \frac{21}{8}\\
	%%%%%%%%%%%%%% 6a operación
	\begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & 1 & -\frac{2}{21} & -\frac{1}{42} & -\frac{1}{14} & 0\\
	0 & 0 & 1 & \frac{1}{4} & \frac{3}{4} & \frac{21}{8}
	\end{pmatrix} &= \begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & 1 & 0 & 0 & \frac{1}{4} & 0\\
	0 & 0 & 1 & \frac{1}{4} & \frac{3}{4} & \frac{21}{8}
	\end{pmatrix} && \text{3a fila $ \* \frac{2}{21} $ + 2a fila en 2a fila}\\
	%%%%%%%%%%%%%%% 7a operación %%%%%%%%%%%%
	\begin{pmatrix}[ccc|ccc]
	1 & 1 & -\frac{1}{3} & -\frac{1}{3} & 0 & 0\\
	0 & 1 & 0 & 0 & \frac{1}{4} & 0\\
	0 & 0 & 1 & \frac{1}{4} & \frac{3}{4} & \frac{21}{8}
	\end{pmatrix}  &= \begin{pmatrix}[ccc|ccc]
	1 & 1 & 0 & -\frac{1}{4} & \frac{1}{4} & \frac{7}{8} \\
	0 & 1 & 0 & 0 & \frac{1}{4} & 0\\
	0 & 0 & 1 & \frac{1}{4} & \frac{3}{4} & \frac{21}{8}
	\end{pmatrix}  && \text{3a fila $ \* \frac{1}{3} + $ 1a fila en 1a fila } \\
	%%%%%%%%%%%%% 8a operación %%%%%%
	\begin{pmatrix}[ccc|ccc]
	1 & 1 & 0 & -\frac{1}{4} & \frac{1}{4} & \frac{7}{8} \\
	0 & 1 & 0 & 0 & \frac{1}{4} & 0\\
	0 & 0 & 1 & \frac{1}{4} & \frac{3}{4} & \frac{21}{8}
	\end{pmatrix} &= \begin{pmatrix}[ccc|ccc]
	1 & 0 & 0 & -\frac{1}{4} & \frac{1}{4} & \frac{5}{8} \\
	0 & 1 & 0 & 0 & \frac{1}{4} & 0\\
	0 & 0 & 1 & \frac{1}{4} & \frac{3}{4} & \frac{21}{8}
	\end{pmatrix} && \text{2a fila $ \* -1 + $ 1a fila en 1a fila}
\end{align*}
Así hemos encontrado la solución al sistema de equaciónes planteado
\begin{center}
	$ \therefore \qquad <\beta'> = \Po$
\end{center}
Ahora veamos si es linealmente independiente, para ello, debe ocurrir que la única solución a \[ \alpha_1(-3 + x) + \alpha_2(-3 -13x + 4x^2) + \alpha_3(1 + x) = 0 \]
sea que $$ \alpha_1 = \alpha_2 =  \alpha_3 = 0 $$
entonces obtenemos el siguiente sistema
\begin{align*}
\begin{pmatrix}[ccc|c]
-3 & -3 & 1 & 0 \\
1 & -13 & 1 & 0\\
0 & 4 & 0 & 0 
\end{pmatrix} &= \begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
1 & -13 & 1 & 0 \\
0 & 4 & 0 & 0 
\end{pmatrix} && \text{1a fila } \* -\frac{1}{3}\\
%%%%%%%%%%%%%% 2da operacion %%%%%%%%%%%%%
\begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3}  0\\
1 & -13 & 1 & 0\\
0 & 4 & 0 & 0
\end{pmatrix} &= \begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} &  0\\
0 & -14 & \frac{4}{3} & 0\\
0 & 4 & 0 & 0 
\end{pmatrix} && \text{1a fila $ \* -1 + 2^a$ Fila en 2a fila }\\
%%%%%%%%% 3a operación %%%%%%%%
\begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
0 & -14 & \frac{4}{3} &0\\
0 & 4 & 0 & 0 
\end{pmatrix} &= \begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
0 & 1 & -\frac{2}{21} & 0\\
0 & 4 & 0 & 0
\end{pmatrix} && \text{2a fila } \* - \frac{1}{14}\\
%%%%%%%%% 4a operacion 
\begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
0 & 1 & -\frac{2}{21} & 0\\
0 & 4 & 0 & 0
\end{pmatrix}  &= \begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
0 & 1 & -\frac{2}{21} & 0\\
0 & 0 & \frac{8}{21} & 0
\end{pmatrix}  && \text{2a fila $ \* -4 $ + 3a fila en 3a fila } \\
%%%%%%%%% 5a opreracion %%%%%%%%%
\begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
0 & 1 & -\frac{2}{21} & 0\\
0 & 0 & \frac{8}{21} & 0
\end{pmatrix}  & = \begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
0 & 1 & -\frac{2}{21} & 0\\
0 & 0 & 1 & 0
\end{pmatrix}  && \text{3a fila } \* \frac{21}{8}\\
%%%%%%%%%%%%%% 6a operación
\begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
0 & 1 & -\frac{2}{21} & 0\\
0 & 0 & 1 & 0
\end{pmatrix} &= \begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0
\end{pmatrix} && \text{3a fila $ \* \frac{2}{21} $ + 2a fila en 2a fila}\\
%%%%%%%%%%%%%%% 7a operación %%%%%%%%%%%%
\begin{pmatrix}[ccc|c]
1 & 1 & -\frac{1}{3} & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0
\end{pmatrix}  &= \begin{pmatrix}[ccc|c]
1 & 1 & 0 & 0 \\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0
\end{pmatrix}  && \text{3a fila $ \* \frac{1}{3} + $ 1a fila en 1a fila } \\
%%%%%%%%%%%%% 8a operación %%%%%%
\begin{pmatrix}[ccc|ccc]
1 & 1 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0
\end{pmatrix} &= \begin{pmatrix}[ccc|ccc]
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0
\end{pmatrix} && \text{2a fila $ \* -1 + $ 1a fila en 1a fila}
\end{align*}
\begin{center}
	$ \therefore \qquad \beta' $ es linealmente independiete\\
	$ \therefore \qquad \beta' $ es base para $ \Po $
\end{center}


\end{document}
